{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0985d7e8-6cd4-4f12-a377-d29416dd7719",
   "metadata": {},
   "source": [
    "## Set Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9d466b-dbe6-4ce7-b583-323b4e689cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def initialize_board():\n",
    "    return np.zeros((3, 3), dtype=int)\n",
    "\n",
    "def print_board(board):\n",
    "    for row in board:\n",
    "        print(\" | \".join([\"X\" if cell == 1 else \"O\" if cell == -1 else \" \" for cell in row]))\n",
    "        print(\"-\" * 9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb60e3d-c70c-48d5-8d06-827f189a942a",
   "metadata": {},
   "source": [
    "## Define Game Mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e3a298-0df9-4e04-84a4-0e365f75e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_winner(board):\n",
    "    for i in range(3):\n",
    "        if abs(sum(board[i, :])) == 3:  \n",
    "            return board[i, 0]\n",
    "        if abs(sum(board[:, i])) == 3:  \n",
    "            return board[0, i]\n",
    "    if abs(sum(board.diagonal())) == 3:  \n",
    "        return board[0, 0]\n",
    "    if abs(sum(np.fliplr(board).diagonal())) == 3: \n",
    "        return board[0, 2]\n",
    "    \n",
    "    if not 0 in board:  \n",
    "        return 0\n",
    "    return None  \n",
    "\n",
    "def get_possible_moves(board):\n",
    "    return [(i, j) for i in range(3) for j in range(3) if board[i, j] == 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f136f7c1-72a2-434a-9406-8b0c40f339ba",
   "metadata": {},
   "source": [
    "## Build the Q-Learning Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5bfc90-15d9-4d65-9b59-eafb150b8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table = {}\n",
    "\n",
    "def initialize_q_values(state):\n",
    "    if state not in Q_table:\n",
    "        Q_table[state] = {move: 0 for move in get_possible_moves(np.array(eval(state)))}\n",
    "        \n",
    "def update_q_values(state, action, reward, next_state, alpha=0.1, gamma=0.9):\n",
    "    max_future_q = max(Q_table.get(next_state, {}).values(), default=0)\n",
    "    current_q = Q_table[state][action]\n",
    "    Q_table[state][action] += alpha * (reward + gamma * max_future_q - current_q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624028ec-ce1a-44b6-84df-534a8dc9d1e1",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab5814a-ae22-4ef4-bdd9-e7253af6e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_episodes=10000, epsilon=0.1):\n",
    "    for _ in range(num_episodes):\n",
    "        board = initialize_board()\n",
    "        state = str(board.tolist())\n",
    "        done = False\n",
    "        while not done:\n",
    "            \n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = random.choice(get_possible_moves(board))\n",
    "            else:\n",
    "                initialize_q_values(state)\n",
    "                action = max(Q_table[state], key=Q_table[state].get)\n",
    "              \n",
    "            board[action] = 1\n",
    "            next_state = str(board.tolist())\n",
    "            reward = 0\n",
    "            winner = check_winner(board)\n",
    "            if winner == 1: reward = 1  \n",
    "            elif winner == 0: reward = 0.5  \n",
    "            elif winner == -1: reward = -1  \n",
    "            done = winner is not None\n",
    "            \n",
    "            if not done:\n",
    "                opponent_move = random.choice(get_possible_moves(board))\n",
    "                board[opponent_move] = -1\n",
    "                done = check_winner(board) is not None\n",
    "                next_state = str(board.tolist())\n",
    "            \n",
    "            initialize_q_values(state)\n",
    "            initialize_q_values(next_state)\n",
    "            update_q_values(state, action, reward, next_state)\n",
    "            state = next_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67282885-66c6-4639-a202-8dd25f6fce03",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71f510e-70bc-4a0a-a203-2705c294bcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "X |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   | O\n",
      "---------\n",
      "X | X |  \n",
      "---------\n",
      "O |   |  \n",
      "---------\n",
      "  |   | O\n",
      "---------\n",
      "Agent wins!\n",
      "X | X | X\n",
      "---------\n",
      "O |   |  \n",
      "---------\n",
      "  |   | O\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    board = initialize_board()\n",
    "    state = str(board.tolist())\n",
    "    done = False\n",
    "    while not done:\n",
    "        print_board(board)\n",
    "        \n",
    "        # Initialize Q-values for the current state if not already in Q_table\n",
    "        if state not in Q_table:\n",
    "            initialize_q_values(state)\n",
    "        \n",
    "      \n",
    "        action = max(Q_table[state], key=Q_table[state].get)\n",
    "        \n",
    "        # Take action (agent's move)\n",
    "        board[action] = 1\n",
    "        if check_winner(board) == 1:\n",
    "            print(\"Agent wins!\")\n",
    "            break\n",
    "        elif check_winner(board) == 0:\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "        \n",
    "        # Opponent's random move\n",
    "        opponent_move = random.choice(get_possible_moves(board))\n",
    "        board[opponent_move] = -1\n",
    "        if check_winner(board) == -1:\n",
    "            print(\"Opponent wins!\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        state = str(board.tolist())\n",
    "    print_board(board)\n",
    "\n",
    "# Run the test function to play against the trained model\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04a42c-a3b9-4bdf-8bda-4727c4c534b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
